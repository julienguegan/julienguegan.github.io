<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="fr" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Optimisation : algorithme, XFOIL, profil d’aile - Blog du Julien</title>
<meta name="description" content="Dans la vie de tous les jours, on cherche souvent à optimiser nos actions pour faire le moins d’effort et bien, dans le monde de l’ingénierie, c’est la même chose. Les problèmes de minimisation sont omniprésents dans de nombreux systèmes que ce soit pour obtenir un gain de temps, d’argent, d’énergie, de matière première, ou encore de satisfaction. On peut par exemple chercher à optimiser un trajet, la forme d’un objet, un prix de vente, une réaction chimique, le contrôle aérien, le rendement d’un appareil, le fonctionnement d’un moteur … La complexité des problèmes et de leur modélisation fait de l’optimisation une branche des mathématiques très vaste et variée, en pratique la qualité des résultats dépend de la pertinence du modèle, du bon choix des variables que l’on cherche à optimiser, de l’efficacité de l’algorithme et des moyens pour le traitement numérique. Dans le domaine de l’aérodynamisme, la forme des avions et des voitures de courses est souvent designer pour que l’énergie dépensée soit minimum. Après avoir introduit quelques aspects algorithmiques du problème de minimisation, l’article suivant présentera comment le profil d’une aile d’avion peut être optimisé pour maximiser ses performances.         Algorithmes d’optimisation  Face à la résolution d’un problème d’optimisation, une 1ère étape est d’identifier à quelle catégorie il appartient. En effet, les algorithmes sont plus ou moins adaptés pour des catégories données puisque le problème peut être continue ou discret, avec ou sans contraintes, différentiable ou non, convexe ou non … On écrit un problème d’optimisation sans contraintes simplement :  [\min_{x \in X} f(x)]  où $f$ peut être appelée fonction objectif ou fonction coût. En théorie, pour des problèmes non contraints, on peut trouver le(s) minimum(s) en regardant quand $ \nabla f(x) = 0 $ (condition du premier ordre) et la positivité de la hessienne $H(x)$ (condition du second ordre). Pour un problème avec contraintes, les conditions de Kuhn-Tucker appliquées à la fonction Lagrangienne permettent de transformer le problème en un nouveau sans contraintes mais avec des inconnues supplémentaires.  Note: Un problème de maximisation peut être facilement transposer en un problème de minimisation :  \(\max_{x \in X} f(x) \Leftrightarrow \min_{x \in X} - f(x)\)  Pour des cas simples, on peut donc résoudre analytiquement le problème. Par exemple, lorsque $f$ a une forme quadratique, linéaire et sans contrainte, annuler le gradient revient à résoudre un système linéaire. Mais, en pratique, le gradient peut avoir une forme trop compliqué ou même la fonction $f$ peut ne pas avoir de forme analytique connue (elle peut être le résultat d’une d’EDP résolu numériquement par exemple). Il existe donc une grande variété d’algorithmes d’optimisation itératifs pour essayer de trouver le minimum, certains étant plus ou moins adaptés à certains type de problème. D’autre part, il est courant de valider ces algorithmes en les testant sur des fonctions connues pour lesquelles on connaît analytiquement la valeur du vraie mimimum, elles permettent d’évaluer les caractéristiques des approches comme la vitesse de convergence, la robustesses, la précision ou le comportement général. Une liste assez complète de ces fonctions test est disponible sur wikipedia.  Par soucis de simplicité, les 3 approches ci-dessous sont des approches simples qui permettent d’introduisent les notions basiques des algorithmes d’optimisation, elles seront testées sur la fonction test de Himmelblau. Dans la réalité, on fait le plus souvent appelle a des librairies ou logiciels spécialisés qui implémentent des approches bien plus sophistiquées.  todo : afficher fonction himmelblau - interactive 3D plotly  Descente de gradient   L’algorithme de descente de gradient permet de minimiser des fonctions réelles différentiables. Cette approche itérative améliore successivement le point recherché en se déplacement dans la direction opposé au gradient de façon à faire décroître la fonction objectif. Dans sa version simple, l’algorithme trouve un minimum local (et pas global) et peut présenter certains inconvénients comme par exemple la difficulté à converger si le paramètre $\alpha$ (le pas de la descente) est mal réglé. Il existe tout une famille de méthodes dites à directions de descente qui exploitent le gradient pour converger le minimum de $f$ de façon plus efficace.  def gradient_descent(f, x0, gradient, alpha=0.01, itermax=1000):     # initialization     x, fx = np.zeros((itermax+1, len(x0))), np.zeros((itermax+1, 1))     x[0,:] = x0     # iterative loop     k = 0     while (k &lt; itermax):         grad_fxk = gradient(f, x[k,:]) # use analytical expression or numerical approximation         x[k+1,:] = x[k,:] - alpha * grad_fxk         k = k+1     return x   Note: Si le pas de descente $\alpha$ est trop petit, l’algorithme risque de converger trop lentement (voir jamais). Si $\alpha$ est trop grand, l’algorithme peut diverger (notamment en zigzaguant dans les vallées étroites)  Nelder-Mead   Un problème majeur des algorithmes à directions de descente est qu’elles sont surtout efficaces pour des fonctions différentiables et lorsqu’on connaît l’expression exacte du gradient de $f$. On peut néanmoins approximer le gradient par schéma numérique mais l’approximation faite rend souvent cette approche inefficace. La méthode de Nelder-Mead est une méthode qui exploite le concept de simplexe : une figure de $N+1$ sommets pour un espace à $N$ dimensions. L’idée consiste, à chaque itération, d’évaluer la valeur de la fonction $f$ à chaque point du simplexe et, selon ses valeurs, effectuer des transformations géométriques du simplexe (réflexion, expansion, contraction). Par exemple, dans une vallée, le simplexe sera étiré dans la direction où $f$ diminue. Bien que simple, cet algorithme permet de trouver un minimum sans calcul de gradient cependant il est moins efficace quand la dimension d’entrée $N$ est grande.  def nelder_mead(f, x0, params=2, itermax=1000):     c = params        # initialization     x1, x2, x3 = np.array([[x0[0]-0.5,x0[1]],[x0[0],x0[1]],[x0[0],x0[1]+0.5]])     x  = np.array([x1, x2, x3])     xm = np.zeros((itermax+1, len(x0)))     # iterative loop     k = 0     while (k &lt; itermax):         # SORT SIMPLEX         A = f(x.T)         index = np.argsort(A)          x_min, x_max, x_bar = x[index[0],:], x[index[2],:], (x[index[0],:] + x[index[1],:])/2         # REFLECTION         x_refl = x_bar + (x_bar - x_max)         # EXPANSION         if f(x_refl) &lt; f(x_min):              x_exp = x_bar + 2*(x_bar - x_max)             if f(x_exp) &lt; f(x_refl):                 x_max = x_exp             else:                 x_max = x_refl         elif (f(x_min) &lt; f(x_refl)) and (f(x_refl) &lt; f(x_max)):             x_max = x_refl          # CONTRACTION         else:              x_con = x_bar - (x_bar - x_max)/2             if f(x_con) &lt; f(x_min):                 x_max = x_con             else:                 x[index[1],:] = x_max + (x[index[1],:] - x_min)/2         # UPDATE DATAs         x = np.array([x_max, x[index[1],:], x_min])         xm[k+1,:] = x_bar         k = k+1     return xm[:k+1,:]   Attention: Comme la descente de gradient, la méthode de Nelder-Mead converge vers un minimum local de la fonction $f$ et non global. Il est toutefois possible de redémarrer l’algorithme avec une valeur d’initialisation $x_0$ différente pour espérer converger vers un nouveau minimum plus petit.  Stratégie d’évolution   Les méthodes présentées précédemment sont capables de trouver des minima mais des minima locaux et non globaux. Les techniques dites stratégies d’évolution sont des métaheuristiques inspirées de la théorie de l’évolution qui converge statistiquement vers un minimum global. L’idée est de partir d’une population de $\mu$ parents qui vont produire $\lambda$ enfants. Parmis ces $\lambda$ enfants, seuls ceux les mieux sont sélectionné pour faire partie de la prochaine génération. Le vocabulaire utilisé est celui de l’évolution mais, en pratique, on fait des tirages aléatoires de points et on garde ceux pour lesquelles la fonction $f$ est minimale. Cet algorithme peut trouver un minimum global mais l’inconvénient principal est qu’il nécessite un grand nombre d’évaluation de la fonction $f$ ce qui est généralement coûteux en temps de calcul.  def evolution_strategy(f, x0, params=[5,3,1], itermax=1000):     # parameters     dim = len(x0)     lambd, mu, tau = params     # initialization     x, xp, s = np.zeros((itermax+1, dim)), np.zeros((itermax+1, lambd, dim)), np.zeros((itermax+1, dim))     x[0,:] = x0     s[0,:] = [0.1,0.1]     # ITERATIVE LOOP     k = 0     while (k &lt; itermax):         # GENERATION         sp = s[k,:] * np.exp(tau * randn(lambd, dim))         xp[k,:,:] = x[k,:] + sp * randn(lambd, dim)         Zp = [f(xi) for xi in xp[k,:,:]]         # SELECTION         mins = np.argsort(Zp)[:mu]         xc   = xp[k,mins,:]         sc   = sp[mins,:]         # UPDATE         x[k+1,:] = np.mean(xc, 0)         s[k+1,:] = np.mean(sc, 0)         k = k+1     return x[:k+1,:]   Problème d’aérodynamisme  Imaginons qu’on veuille créer un avion d’un poids de $P=6 kg$ et qui aura une vitesse moyenne de vol de $V=12 m/s$, le problème est de designer les ailes de l’avion de telle façon que l’énergie qui sera dépensée soit minimum. Si on considère un vol stationnaire, il existe 4 forces principales qui s’opposent : la poussée (produit par les moteurs), la trainée ( due à la résistance de l’air, le profil de l’aile, la compressibilité …), le poids (gravité terrestre), et la portance (plus d’infos chez science étonnante). Le but de notre problème d’optimisation du profil d’aile est donc de trouver une forme d’aile qui minimisera la trainée et maximisera la portance. La portance verticale $F_y$ d’une aile et la trainée horizontale $F_x$ sont calculées grâce aux formules suivantes issues de la mécanique des fluides :  [F_y = \frac{1}{2}\, \rho\, S\, V^2\, C_y  \quad \text{et} \quad  F_x = \frac{1}{2}\, \rho\, S\, V^2\, C_x]  avec    $\rho$ la masse volumique de l’air ($kg/m^3$)   $S$ la surface de l’aile ($m^2$)   $V$ la vitesse ($m/s$)   $C_y$ le coefficient de portance   $C_x$ le coefficient de trainée   Finalement, la fonction à minimiser s’écrit :  [f(x) = F_x + \max(0, P - F_y)]  avec \(x = \left[ \text{NACA}_{M} \text{, NACA}_{P} \text{, NACA}_{XX} \text{, L, }\alpha \right]\)  # constantes poids = 6 Ro    = 1 V     = 12 # function to minimize def cost_function(x):     # call xfoil     write_xfoil(x)     os.system(r&#39;xfoil.exe &lt; input.dat&#39;)     CL, CD = read_xfoil()     # compute COST function     L  = x[3]     c  = (1/10)*L     S  = L*c     Fx = 0.5*Ro*S*V**2*CD     Fy = 0.5*Ro*S*V**2*CL     y  = Fx + max(0, poids-Fy)     return y   Les paramètres à trouver définissant la forme de l’aile sont la géométrie du profil, l’envergure $L$ de l’aile et l’angle d’attaque $\alpha$. La géométrie du profil peut être définie par le code NACA MPXX où M est la cambrure maximale, P le point de cambrure maximal par rapport au bord d’attaque de la corde, et XX l’épaisseur maximale du profil. Par exemple, le profil aérodynamique NACA 2412 possède une cambrure maximale de $2%$ à $40%$ à partir du bord d’attaque avec une épaisseur maximale de 12%. D’autres part, pour simplifier, on supposera que la corde est 10 fois plus petite que l’envergure de l’aile. Ensuite, pour pouvoir évaluer les forces $F_x$ et $F_y$, il est nécessaire de connaître les coefficients $C_y$ et $C_x$. Ces coefficients dépendent de la forme de l’aile ainsi que de grandeurs physiques comme le nombre de Mach $Ma = \frac{v}{a} = \frac{12}{340}$ et le nombre de Reynolds $Re = \frac{\rho v L}{\mu} = \frac{12L}{1.8 10^{-5}}$, l’estimation de $C_x$ et $C_y$ n’est pas un problème évident. Mais des solveurs aérodynamiques comme XFOIL implémentent des outils pour calculer ces coefficients (cf page 16). L’idée est donc d’executer des commandes XFOIL et de récupérer sa sortie à chaque fois que la fonction coût $f$ doit être évaluée.  def read_xfoil():     with open(&quot;results.dat&quot;, &quot;r&quot;) as file:         coeffs = file.readlines()[-1]     CL = float(coeffs.split()[1])     CD = float(coeffs.split()[2])     return CL, CD  def write_xfoil(x):     NACAx, NACAy  = int(x[0]), int(x[1])     NACAep, alpha = int(x[2]), x[4]     corde    = (1/10)*x[3]     mach     = 12/340     reynolds = corde*12./(1.8*10e-5)     # write command in file     file = open(&quot;input.dat&quot;, &quot;w&quot;)     file.write(&quot;plop\ng\n\n&quot;)     file.write(&quot;naca &quot;+str(NACAx)+str(NACAy)+str(NACAep)+&quot;\n\noper\n&quot;)     file.write(&quot;mach &quot;+str(mach)+&quot;\n&quot;)     file.write(&quot;visc &quot;+str(reynolds)+&quot;\n&quot;)     file.write(&quot;pacc\nresults.dat\ny\n\n&quot;)     file.write(&quot;alfa &quot;+str(alpha)+&quot;\n\nquit&quot;)     file.close()   Maintenant qu’on est capable de calculer la fonction $f$ à minimiser, on peut appliquer un algorithme d’optimisation. Étant que les méthodes présentées dans la section précédente sont basiques, il n’y a pas de honte à utiliser directement des librairies comme Scipy qui implémente la métaheuristique du recuit simulé (s’inspire de processus métallurgique). Scipy possède plusieurs autres algorithmes d’optimisation mais, après expériences, c’est celui-ci qui semblait être le plus efficace.  from scipy import optimize x0 = np.array([2, 4, 12, 5, 5]) bounds = [(0,4),(2,8),(10,20),(2,6),(0,10)] optimize.dual_annealing(cost_function, bounds, x0=x0, maxiter=10)          todo : aerosandbox">


  <meta name="author" content="Julien Guégan">
  
  <meta property="article:author" content="Julien Guégan">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="fr_FR">
<meta property="og:site_name" content="Blog du Julien">
<meta property="og:title" content="Optimisation : algorithme, XFOIL, profil d’aile">
<meta property="og:url" content="http://localhost:4000/posts/2021-08-21-optimisation_profil_aile/">


  <meta property="og:description" content="Dans la vie de tous les jours, on cherche souvent à optimiser nos actions pour faire le moins d’effort et bien, dans le monde de l’ingénierie, c’est la même chose. Les problèmes de minimisation sont omniprésents dans de nombreux systèmes que ce soit pour obtenir un gain de temps, d’argent, d’énergie, de matière première, ou encore de satisfaction. On peut par exemple chercher à optimiser un trajet, la forme d’un objet, un prix de vente, une réaction chimique, le contrôle aérien, le rendement d’un appareil, le fonctionnement d’un moteur … La complexité des problèmes et de leur modélisation fait de l’optimisation une branche des mathématiques très vaste et variée, en pratique la qualité des résultats dépend de la pertinence du modèle, du bon choix des variables que l’on cherche à optimiser, de l’efficacité de l’algorithme et des moyens pour le traitement numérique. Dans le domaine de l’aérodynamisme, la forme des avions et des voitures de courses est souvent designer pour que l’énergie dépensée soit minimum. Après avoir introduit quelques aspects algorithmiques du problème de minimisation, l’article suivant présentera comment le profil d’une aile d’avion peut être optimisé pour maximiser ses performances.         Algorithmes d’optimisation  Face à la résolution d’un problème d’optimisation, une 1ère étape est d’identifier à quelle catégorie il appartient. En effet, les algorithmes sont plus ou moins adaptés pour des catégories données puisque le problème peut être continue ou discret, avec ou sans contraintes, différentiable ou non, convexe ou non … On écrit un problème d’optimisation sans contraintes simplement :  [\min_{x \in X} f(x)]  où $f$ peut être appelée fonction objectif ou fonction coût. En théorie, pour des problèmes non contraints, on peut trouver le(s) minimum(s) en regardant quand $ \nabla f(x) = 0 $ (condition du premier ordre) et la positivité de la hessienne $H(x)$ (condition du second ordre). Pour un problème avec contraintes, les conditions de Kuhn-Tucker appliquées à la fonction Lagrangienne permettent de transformer le problème en un nouveau sans contraintes mais avec des inconnues supplémentaires.  Note: Un problème de maximisation peut être facilement transposer en un problème de minimisation :  \(\max_{x \in X} f(x) \Leftrightarrow \min_{x \in X} - f(x)\)  Pour des cas simples, on peut donc résoudre analytiquement le problème. Par exemple, lorsque $f$ a une forme quadratique, linéaire et sans contrainte, annuler le gradient revient à résoudre un système linéaire. Mais, en pratique, le gradient peut avoir une forme trop compliqué ou même la fonction $f$ peut ne pas avoir de forme analytique connue (elle peut être le résultat d’une d’EDP résolu numériquement par exemple). Il existe donc une grande variété d’algorithmes d’optimisation itératifs pour essayer de trouver le minimum, certains étant plus ou moins adaptés à certains type de problème. D’autre part, il est courant de valider ces algorithmes en les testant sur des fonctions connues pour lesquelles on connaît analytiquement la valeur du vraie mimimum, elles permettent d’évaluer les caractéristiques des approches comme la vitesse de convergence, la robustesses, la précision ou le comportement général. Une liste assez complète de ces fonctions test est disponible sur wikipedia.  Par soucis de simplicité, les 3 approches ci-dessous sont des approches simples qui permettent d’introduisent les notions basiques des algorithmes d’optimisation, elles seront testées sur la fonction test de Himmelblau. Dans la réalité, on fait le plus souvent appelle a des librairies ou logiciels spécialisés qui implémentent des approches bien plus sophistiquées.  todo : afficher fonction himmelblau - interactive 3D plotly  Descente de gradient   L’algorithme de descente de gradient permet de minimiser des fonctions réelles différentiables. Cette approche itérative améliore successivement le point recherché en se déplacement dans la direction opposé au gradient de façon à faire décroître la fonction objectif. Dans sa version simple, l’algorithme trouve un minimum local (et pas global) et peut présenter certains inconvénients comme par exemple la difficulté à converger si le paramètre $\alpha$ (le pas de la descente) est mal réglé. Il existe tout une famille de méthodes dites à directions de descente qui exploitent le gradient pour converger le minimum de $f$ de façon plus efficace.  def gradient_descent(f, x0, gradient, alpha=0.01, itermax=1000):     # initialization     x, fx = np.zeros((itermax+1, len(x0))), np.zeros((itermax+1, 1))     x[0,:] = x0     # iterative loop     k = 0     while (k &lt; itermax):         grad_fxk = gradient(f, x[k,:]) # use analytical expression or numerical approximation         x[k+1,:] = x[k,:] - alpha * grad_fxk         k = k+1     return x   Note: Si le pas de descente $\alpha$ est trop petit, l’algorithme risque de converger trop lentement (voir jamais). Si $\alpha$ est trop grand, l’algorithme peut diverger (notamment en zigzaguant dans les vallées étroites)  Nelder-Mead   Un problème majeur des algorithmes à directions de descente est qu’elles sont surtout efficaces pour des fonctions différentiables et lorsqu’on connaît l’expression exacte du gradient de $f$. On peut néanmoins approximer le gradient par schéma numérique mais l’approximation faite rend souvent cette approche inefficace. La méthode de Nelder-Mead est une méthode qui exploite le concept de simplexe : une figure de $N+1$ sommets pour un espace à $N$ dimensions. L’idée consiste, à chaque itération, d’évaluer la valeur de la fonction $f$ à chaque point du simplexe et, selon ses valeurs, effectuer des transformations géométriques du simplexe (réflexion, expansion, contraction). Par exemple, dans une vallée, le simplexe sera étiré dans la direction où $f$ diminue. Bien que simple, cet algorithme permet de trouver un minimum sans calcul de gradient cependant il est moins efficace quand la dimension d’entrée $N$ est grande.  def nelder_mead(f, x0, params=2, itermax=1000):     c = params        # initialization     x1, x2, x3 = np.array([[x0[0]-0.5,x0[1]],[x0[0],x0[1]],[x0[0],x0[1]+0.5]])     x  = np.array([x1, x2, x3])     xm = np.zeros((itermax+1, len(x0)))     # iterative loop     k = 0     while (k &lt; itermax):         # SORT SIMPLEX         A = f(x.T)         index = np.argsort(A)          x_min, x_max, x_bar = x[index[0],:], x[index[2],:], (x[index[0],:] + x[index[1],:])/2         # REFLECTION         x_refl = x_bar + (x_bar - x_max)         # EXPANSION         if f(x_refl) &lt; f(x_min):              x_exp = x_bar + 2*(x_bar - x_max)             if f(x_exp) &lt; f(x_refl):                 x_max = x_exp             else:                 x_max = x_refl         elif (f(x_min) &lt; f(x_refl)) and (f(x_refl) &lt; f(x_max)):             x_max = x_refl          # CONTRACTION         else:              x_con = x_bar - (x_bar - x_max)/2             if f(x_con) &lt; f(x_min):                 x_max = x_con             else:                 x[index[1],:] = x_max + (x[index[1],:] - x_min)/2         # UPDATE DATAs         x = np.array([x_max, x[index[1],:], x_min])         xm[k+1,:] = x_bar         k = k+1     return xm[:k+1,:]   Attention: Comme la descente de gradient, la méthode de Nelder-Mead converge vers un minimum local de la fonction $f$ et non global. Il est toutefois possible de redémarrer l’algorithme avec une valeur d’initialisation $x_0$ différente pour espérer converger vers un nouveau minimum plus petit.  Stratégie d’évolution   Les méthodes présentées précédemment sont capables de trouver des minima mais des minima locaux et non globaux. Les techniques dites stratégies d’évolution sont des métaheuristiques inspirées de la théorie de l’évolution qui converge statistiquement vers un minimum global. L’idée est de partir d’une population de $\mu$ parents qui vont produire $\lambda$ enfants. Parmis ces $\lambda$ enfants, seuls ceux les mieux sont sélectionné pour faire partie de la prochaine génération. Le vocabulaire utilisé est celui de l’évolution mais, en pratique, on fait des tirages aléatoires de points et on garde ceux pour lesquelles la fonction $f$ est minimale. Cet algorithme peut trouver un minimum global mais l’inconvénient principal est qu’il nécessite un grand nombre d’évaluation de la fonction $f$ ce qui est généralement coûteux en temps de calcul.  def evolution_strategy(f, x0, params=[5,3,1], itermax=1000):     # parameters     dim = len(x0)     lambd, mu, tau = params     # initialization     x, xp, s = np.zeros((itermax+1, dim)), np.zeros((itermax+1, lambd, dim)), np.zeros((itermax+1, dim))     x[0,:] = x0     s[0,:] = [0.1,0.1]     # ITERATIVE LOOP     k = 0     while (k &lt; itermax):         # GENERATION         sp = s[k,:] * np.exp(tau * randn(lambd, dim))         xp[k,:,:] = x[k,:] + sp * randn(lambd, dim)         Zp = [f(xi) for xi in xp[k,:,:]]         # SELECTION         mins = np.argsort(Zp)[:mu]         xc   = xp[k,mins,:]         sc   = sp[mins,:]         # UPDATE         x[k+1,:] = np.mean(xc, 0)         s[k+1,:] = np.mean(sc, 0)         k = k+1     return x[:k+1,:]   Problème d’aérodynamisme  Imaginons qu’on veuille créer un avion d’un poids de $P=6 kg$ et qui aura une vitesse moyenne de vol de $V=12 m/s$, le problème est de designer les ailes de l’avion de telle façon que l’énergie qui sera dépensée soit minimum. Si on considère un vol stationnaire, il existe 4 forces principales qui s’opposent : la poussée (produit par les moteurs), la trainée ( due à la résistance de l’air, le profil de l’aile, la compressibilité …), le poids (gravité terrestre), et la portance (plus d’infos chez science étonnante). Le but de notre problème d’optimisation du profil d’aile est donc de trouver une forme d’aile qui minimisera la trainée et maximisera la portance. La portance verticale $F_y$ d’une aile et la trainée horizontale $F_x$ sont calculées grâce aux formules suivantes issues de la mécanique des fluides :  [F_y = \frac{1}{2}\, \rho\, S\, V^2\, C_y  \quad \text{et} \quad  F_x = \frac{1}{2}\, \rho\, S\, V^2\, C_x]  avec    $\rho$ la masse volumique de l’air ($kg/m^3$)   $S$ la surface de l’aile ($m^2$)   $V$ la vitesse ($m/s$)   $C_y$ le coefficient de portance   $C_x$ le coefficient de trainée   Finalement, la fonction à minimiser s’écrit :  [f(x) = F_x + \max(0, P - F_y)]  avec \(x = \left[ \text{NACA}_{M} \text{, NACA}_{P} \text{, NACA}_{XX} \text{, L, }\alpha \right]\)  # constantes poids = 6 Ro    = 1 V     = 12 # function to minimize def cost_function(x):     # call xfoil     write_xfoil(x)     os.system(r&#39;xfoil.exe &lt; input.dat&#39;)     CL, CD = read_xfoil()     # compute COST function     L  = x[3]     c  = (1/10)*L     S  = L*c     Fx = 0.5*Ro*S*V**2*CD     Fy = 0.5*Ro*S*V**2*CL     y  = Fx + max(0, poids-Fy)     return y   Les paramètres à trouver définissant la forme de l’aile sont la géométrie du profil, l’envergure $L$ de l’aile et l’angle d’attaque $\alpha$. La géométrie du profil peut être définie par le code NACA MPXX où M est la cambrure maximale, P le point de cambrure maximal par rapport au bord d’attaque de la corde, et XX l’épaisseur maximale du profil. Par exemple, le profil aérodynamique NACA 2412 possède une cambrure maximale de $2%$ à $40%$ à partir du bord d’attaque avec une épaisseur maximale de 12%. D’autres part, pour simplifier, on supposera que la corde est 10 fois plus petite que l’envergure de l’aile. Ensuite, pour pouvoir évaluer les forces $F_x$ et $F_y$, il est nécessaire de connaître les coefficients $C_y$ et $C_x$. Ces coefficients dépendent de la forme de l’aile ainsi que de grandeurs physiques comme le nombre de Mach $Ma = \frac{v}{a} = \frac{12}{340}$ et le nombre de Reynolds $Re = \frac{\rho v L}{\mu} = \frac{12L}{1.8 10^{-5}}$, l’estimation de $C_x$ et $C_y$ n’est pas un problème évident. Mais des solveurs aérodynamiques comme XFOIL implémentent des outils pour calculer ces coefficients (cf page 16). L’idée est donc d’executer des commandes XFOIL et de récupérer sa sortie à chaque fois que la fonction coût $f$ doit être évaluée.  def read_xfoil():     with open(&quot;results.dat&quot;, &quot;r&quot;) as file:         coeffs = file.readlines()[-1]     CL = float(coeffs.split()[1])     CD = float(coeffs.split()[2])     return CL, CD  def write_xfoil(x):     NACAx, NACAy  = int(x[0]), int(x[1])     NACAep, alpha = int(x[2]), x[4]     corde    = (1/10)*x[3]     mach     = 12/340     reynolds = corde*12./(1.8*10e-5)     # write command in file     file = open(&quot;input.dat&quot;, &quot;w&quot;)     file.write(&quot;plop\ng\n\n&quot;)     file.write(&quot;naca &quot;+str(NACAx)+str(NACAy)+str(NACAep)+&quot;\n\noper\n&quot;)     file.write(&quot;mach &quot;+str(mach)+&quot;\n&quot;)     file.write(&quot;visc &quot;+str(reynolds)+&quot;\n&quot;)     file.write(&quot;pacc\nresults.dat\ny\n\n&quot;)     file.write(&quot;alfa &quot;+str(alpha)+&quot;\n\nquit&quot;)     file.close()   Maintenant qu’on est capable de calculer la fonction $f$ à minimiser, on peut appliquer un algorithme d’optimisation. Étant que les méthodes présentées dans la section précédente sont basiques, il n’y a pas de honte à utiliser directement des librairies comme Scipy qui implémente la métaheuristique du recuit simulé (s’inspire de processus métallurgique). Scipy possède plusieurs autres algorithmes d’optimisation mais, après expériences, c’est celui-ci qui semblait être le plus efficace.  from scipy import optimize x0 = np.array([2, 4, 12, 5, 5]) bounds = [(0,4),(2,8),(10,20),(2,6),(0,10)] optimize.dual_annealing(cost_function, bounds, x0=x0, maxiter=10)          todo : aerosandbox">



  <meta property="og:image" content="http://localhost:4000/assets/images/teaser_airflow.jpg">





  <meta property="article:published_time" content="2021-08-22T04:25:30+02:00">






<link rel="canonical" href="http://localhost:4000/posts/2021-08-21-optimisation_profil_aile/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Julien Guégan",
      "url": "http://localhost:4000/",
      "sameAs": ["https://www.linkedin.com/in/julien-gu%C3%A9gan-852a30138/","https://www.facebook.com/julien.guegan.754","https://github.com/julienguegan","https://www.instagram.com/julien_guegan_/?hl=fr"]
    
  }
</script>


  <meta name="google-site-verification" content="_Cj2FZGjDR1sECXPRL64_CMVDm6adbKqCXSLHArYdSE" />






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Blog du Julien Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="shortcut icon" type="image/png" href="/assets/images/brain_icon.png">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>

<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        // customised options
        // • auto-render specific keys, e.g.:
        delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: '\\(', right: '\\)', display: false},
            {left: '\\[', right: '\\]', display: true}
        ],
        // • rendering keys, e.g.:
        throwOnError : false
      });
  });
</script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/brain_icon.png" alt="Blog du Julien"></a>
        
        <a class="site-title" href="/">
          Blog du Julien
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/home/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/posts/">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/cv/">CV</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/photo_profil.jpg" alt="Julien Guégan" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Julien Guégan</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>Hello, je suis ingénieur en bidouille et j’aime les machins et les trucmuches. Ici, je parle bidule et parfois de chose.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Contact</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="mailto:julienguegan56520@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Mail</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/julien-gu%C3%A9gan-852a30138/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">Linkedin</span></a></li>
          
        
          
            <li><a href="https://www.facebook.com/julien.guegan.754" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i><span class="label">Facebook</span></a></li>
          
        
          
            <li><a href="https://github.com/julienguegan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.instagram.com/julien_guegan_/?hl=fr" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Optimisation : algorithme, XFOIL, profil d’aile">
    <meta itemprop="description" content="Dans la vie de tous les jours, on cherche souvent à optimiser nos actions pour faire le moins d’effort et bien, dans le monde de l’ingénierie, c’est la même chose. Les problèmes de minimisation sont omniprésents dans de nombreux systèmes que ce soit pour obtenir un gain de temps, d’argent, d’énergie, de matière première, ou encore de satisfaction. On peut par exemple chercher à optimiser un trajet, la forme d’un objet, un prix de vente, une réaction chimique, le contrôle aérien, le rendement d’un appareil, le fonctionnement d’un moteur … La complexité des problèmes et de leur modélisation fait de l’optimisation une branche des mathématiques très vaste et variée, en pratique la qualité des résultats dépend de la pertinence du modèle, du bon choix des variables que l’on cherche à optimiser, de l’efficacité de l’algorithme et des moyens pour le traitement numérique. Dans le domaine de l’aérodynamisme, la forme des avions et des voitures de courses est souvent designer pour que l’énergie dépensée soit minimum. Après avoir introduit quelques aspects algorithmiques du problème de minimisation, l’article suivant présentera comment le profil d’une aile d’avion peut être optimisé pour maximiser ses performances.   Algorithmes d’optimisationFace à la résolution d’un problème d’optimisation, une 1ère étape est d’identifier à quelle catégorie il appartient. En effet, les algorithmes sont plus ou moins adaptés pour des catégories données puisque le problème peut être continue ou discret, avec ou sans contraintes, différentiable ou non, convexe ou non … On écrit un problème d’optimisation sans contraintes simplement :[\min_{x \in X} f(x)]où $f$ peut être appelée fonction objectif ou fonction coût. En théorie, pour des problèmes non contraints, on peut trouver le(s) minimum(s) en regardant quand $ \nabla f(x) = 0 $ (condition du premier ordre) et la positivité de la hessienne $H(x)$ (condition du second ordre). Pour un problème avec contraintes, les conditions de Kuhn-Tucker appliquées à la fonction Lagrangienne permettent de transformer le problème en un nouveau sans contraintes mais avec des inconnues supplémentaires.Note: Un problème de maximisation peut être facilement transposer en un problème de minimisation : \(\max_{x \in X} f(x) \Leftrightarrow \min_{x \in X} - f(x)\)Pour des cas simples, on peut donc résoudre analytiquement le problème. Par exemple, lorsque $f$ a une forme quadratique, linéaire et sans contrainte, annuler le gradient revient à résoudre un système linéaire. Mais, en pratique, le gradient peut avoir une forme trop compliqué ou même la fonction $f$ peut ne pas avoir de forme analytique connue (elle peut être le résultat d’une d’EDP résolu numériquement par exemple). Il existe donc une grande variété d’algorithmes d’optimisation itératifs pour essayer de trouver le minimum, certains étant plus ou moins adaptés à certains type de problème. D’autre part, il est courant de valider ces algorithmes en les testant sur des fonctions connues pour lesquelles on connaît analytiquement la valeur du vraie mimimum, elles permettent d’évaluer les caractéristiques des approches comme la vitesse de convergence, la robustesses, la précision ou le comportement général. Une liste assez complète de ces fonctions test est disponible sur wikipedia.Par soucis de simplicité, les 3 approches ci-dessous sont des approches simples qui permettent d’introduisent les notions basiques des algorithmes d’optimisation, elles seront testées sur la fonction test de Himmelblau. Dans la réalité, on fait le plus souvent appelle a des librairies ou logiciels spécialisés qui implémentent des approches bien plus sophistiquées.todo : afficher fonction himmelblau - interactive 3D plotlyDescente de gradient L’algorithme de descente de gradient permet de minimiser des fonctions réelles différentiables. Cette approche itérative améliore successivement le point recherché en se déplacement dans la direction opposé au gradient de façon à faire décroître la fonction objectif. Dans sa version simple, l’algorithme trouve un minimum local (et pas global) et peut présenter certains inconvénients comme par exemple la difficulté à converger si le paramètre $\alpha$ (le pas de la descente) est mal réglé. Il existe tout une famille de méthodes dites à directions de descente qui exploitent le gradient pour converger le minimum de $f$ de façon plus efficace.def gradient_descent(f, x0, gradient, alpha=0.01, itermax=1000):    # initialization    x, fx = np.zeros((itermax+1, len(x0))), np.zeros((itermax+1, 1))    x[0,:] = x0    # iterative loop    k = 0    while (k &lt; itermax):        grad_fxk = gradient(f, x[k,:]) # use analytical expression or numerical approximation        x[k+1,:] = x[k,:] - alpha * grad_fxk        k = k+1    return xNote: Si le pas de descente $\alpha$ est trop petit, l’algorithme risque de converger trop lentement (voir jamais). Si $\alpha$ est trop grand, l’algorithme peut diverger (notamment en zigzaguant dans les vallées étroites)Nelder-Mead Un problème majeur des algorithmes à directions de descente est qu’elles sont surtout efficaces pour des fonctions différentiables et lorsqu’on connaît l’expression exacte du gradient de $f$. On peut néanmoins approximer le gradient par schéma numérique mais l’approximation faite rend souvent cette approche inefficace. La méthode de Nelder-Mead est une méthode qui exploite le concept de simplexe : une figure de $N+1$ sommets pour un espace à $N$ dimensions. L’idée consiste, à chaque itération, d’évaluer la valeur de la fonction $f$ à chaque point du simplexe et, selon ses valeurs, effectuer des transformations géométriques du simplexe (réflexion, expansion, contraction). Par exemple, dans une vallée, le simplexe sera étiré dans la direction où $f$ diminue. Bien que simple, cet algorithme permet de trouver un minimum sans calcul de gradient cependant il est moins efficace quand la dimension d’entrée $N$ est grande.def nelder_mead(f, x0, params=2, itermax=1000):    c = params       # initialization    x1, x2, x3 = np.array([[x0[0]-0.5,x0[1]],[x0[0],x0[1]],[x0[0],x0[1]+0.5]])    x  = np.array([x1, x2, x3])    xm = np.zeros((itermax+1, len(x0)))    # iterative loop    k = 0    while (k &lt; itermax):        # SORT SIMPLEX        A = f(x.T)        index = np.argsort(A)         x_min, x_max, x_bar = x[index[0],:], x[index[2],:], (x[index[0],:] + x[index[1],:])/2        # REFLECTION        x_refl = x_bar + (x_bar - x_max)        # EXPANSION        if f(x_refl) &lt; f(x_min):             x_exp = x_bar + 2*(x_bar - x_max)            if f(x_exp) &lt; f(x_refl):                x_max = x_exp            else:                x_max = x_refl        elif (f(x_min) &lt; f(x_refl)) and (f(x_refl) &lt; f(x_max)):            x_max = x_refl         # CONTRACTION        else:             x_con = x_bar - (x_bar - x_max)/2            if f(x_con) &lt; f(x_min):                x_max = x_con            else:                x[index[1],:] = x_max + (x[index[1],:] - x_min)/2        # UPDATE DATAs        x = np.array([x_max, x[index[1],:], x_min])        xm[k+1,:] = x_bar        k = k+1    return xm[:k+1,:]Attention: Comme la descente de gradient, la méthode de Nelder-Mead converge vers un minimum local de la fonction $f$ et non global. Il est toutefois possible de redémarrer l’algorithme avec une valeur d’initialisation $x_0$ différente pour espérer converger vers un nouveau minimum plus petit.Stratégie d’évolution Les méthodes présentées précédemment sont capables de trouver des minima mais des minima locaux et non globaux. Les techniques dites stratégies d’évolution sont des métaheuristiques inspirées de la théorie de l’évolution qui converge statistiquement vers un minimum global. L’idée est de partir d’une population de $\mu$ parents qui vont produire $\lambda$ enfants. Parmis ces $\lambda$ enfants, seuls ceux les mieux sont sélectionné pour faire partie de la prochaine génération. Le vocabulaire utilisé est celui de l’évolution mais, en pratique, on fait des tirages aléatoires de points et on garde ceux pour lesquelles la fonction $f$ est minimale. Cet algorithme peut trouver un minimum global mais l’inconvénient principal est qu’il nécessite un grand nombre d’évaluation de la fonction $f$ ce qui est généralement coûteux en temps de calcul.def evolution_strategy(f, x0, params=[5,3,1], itermax=1000):    # parameters    dim = len(x0)    lambd, mu, tau = params    # initialization    x, xp, s = np.zeros((itermax+1, dim)), np.zeros((itermax+1, lambd, dim)), np.zeros((itermax+1, dim))    x[0,:] = x0    s[0,:] = [0.1,0.1]    # ITERATIVE LOOP    k = 0    while (k &lt; itermax):        # GENERATION        sp = s[k,:] * np.exp(tau * randn(lambd, dim))        xp[k,:,:] = x[k,:] + sp * randn(lambd, dim)        Zp = [f(xi) for xi in xp[k,:,:]]        # SELECTION        mins = np.argsort(Zp)[:mu]        xc   = xp[k,mins,:]        sc   = sp[mins,:]        # UPDATE        x[k+1,:] = np.mean(xc, 0)        s[k+1,:] = np.mean(sc, 0)        k = k+1    return x[:k+1,:]Problème d’aérodynamismeImaginons qu’on veuille créer un avion d’un poids de $P=6 kg$ et qui aura une vitesse moyenne de vol de $V=12 m/s$, le problème est de designer les ailes de l’avion de telle façon que l’énergie qui sera dépensée soit minimum. Si on considère un vol stationnaire, il existe 4 forces principales qui s’opposent : la poussée (produit par les moteurs), la trainée ( due à la résistance de l’air, le profil de l’aile, la compressibilité …), le poids (gravité terrestre), et la portance (plus d’infos chez science étonnante). Le but de notre problème d’optimisation du profil d’aile est donc de trouver une forme d’aile qui minimisera la trainée et maximisera la portance. La portance verticale $F_y$ d’une aile et la trainée horizontale $F_x$ sont calculées grâce aux formules suivantes issues de la mécanique des fluides :[F_y = \frac{1}{2}\, \rho\, S\, V^2\, C_y  \quad \text{et} \quad  F_x = \frac{1}{2}\, \rho\, S\, V^2\, C_x]avec  $\rho$ la masse volumique de l’air ($kg/m^3$)  $S$ la surface de l’aile ($m^2$)  $V$ la vitesse ($m/s$)  $C_y$ le coefficient de portance  $C_x$ le coefficient de trainéeFinalement, la fonction à minimiser s’écrit :[f(x) = F_x + \max(0, P - F_y)]avec \(x = \left[ \text{NACA}_{M} \text{, NACA}_{P} \text{, NACA}_{XX} \text{, L, }\alpha \right]\)# constantespoids = 6Ro    = 1V     = 12# function to minimizedef cost_function(x):    # call xfoil    write_xfoil(x)    os.system(r&#39;xfoil.exe &lt; input.dat&#39;)    CL, CD = read_xfoil()    # compute COST function    L  = x[3]    c  = (1/10)*L    S  = L*c    Fx = 0.5*Ro*S*V**2*CD    Fy = 0.5*Ro*S*V**2*CL    y  = Fx + max(0, poids-Fy)    return yLes paramètres à trouver définissant la forme de l’aile sont la géométrie du profil, l’envergure $L$ de l’aile et l’angle d’attaque $\alpha$. La géométrie du profil peut être définie par le code NACA MPXX où M est la cambrure maximale, P le point de cambrure maximal par rapport au bord d’attaque de la corde, et XX l’épaisseur maximale du profil. Par exemple, le profil aérodynamique NACA 2412 possède une cambrure maximale de $2%$ à $40%$ à partir du bord d’attaque avec une épaisseur maximale de 12%. D’autres part, pour simplifier, on supposera que la corde est 10 fois plus petite que l’envergure de l’aile. Ensuite, pour pouvoir évaluer les forces $F_x$ et $F_y$, il est nécessaire de connaître les coefficients $C_y$ et $C_x$. Ces coefficients dépendent de la forme de l’aile ainsi que de grandeurs physiques comme le nombre de Mach $Ma = \frac{v}{a} = \frac{12}{340}$ et le nombre de Reynolds $Re = \frac{\rho v L}{\mu} = \frac{12L}{1.8 10^{-5}}$, l’estimation de $C_x$ et $C_y$ n’est pas un problème évident. Mais des solveurs aérodynamiques comme XFOIL implémentent des outils pour calculer ces coefficients (cf page 16). L’idée est donc d’executer des commandes XFOIL et de récupérer sa sortie à chaque fois que la fonction coût $f$ doit être évaluée.def read_xfoil():    with open(&quot;results.dat&quot;, &quot;r&quot;) as file:        coeffs = file.readlines()[-1]    CL = float(coeffs.split()[1])    CD = float(coeffs.split()[2])    return CL, CDdef write_xfoil(x):    NACAx, NACAy  = int(x[0]), int(x[1])    NACAep, alpha = int(x[2]), x[4]    corde    = (1/10)*x[3]    mach     = 12/340    reynolds = corde*12./(1.8*10e-5)    # write command in file    file = open(&quot;input.dat&quot;, &quot;w&quot;)    file.write(&quot;plop\ng\n\n&quot;)    file.write(&quot;naca &quot;+str(NACAx)+str(NACAy)+str(NACAep)+&quot;\n\noper\n&quot;)    file.write(&quot;mach &quot;+str(mach)+&quot;\n&quot;)    file.write(&quot;visc &quot;+str(reynolds)+&quot;\n&quot;)    file.write(&quot;pacc\nresults.dat\ny\n\n&quot;)    file.write(&quot;alfa &quot;+str(alpha)+&quot;\n\nquit&quot;)    file.close()Maintenant qu’on est capable de calculer la fonction $f$ à minimiser, on peut appliquer un algorithme d’optimisation. Étant que les méthodes présentées dans la section précédente sont basiques, il n’y a pas de honte à utiliser directement des librairies comme Scipy qui implémente la métaheuristique du recuit simulé (s’inspire de processus métallurgique). Scipy possède plusieurs autres algorithmes d’optimisation mais, après expériences, c’est celui-ci qui semblait être le plus efficace.from scipy import optimizex0 = np.array([2, 4, 12, 5, 5])bounds = [(0,4),(2,8),(10,20),(2,6),(0,10)]optimize.dual_annealing(cost_function, bounds, x0=x0, maxiter=10)   todo : aerosandbox  ">
    <meta itemprop="datePublished" content="2021-08-22T04:25:30+02:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/posts/2021-08-21-optimisation_profil_aile/" class="u-url" itemprop="url">Optimisation : algorithme, XFOIL, profil d’aile
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute(s) de lecture
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
        <p>Dans la vie de tous les jours, on cherche souvent à optimiser nos actions pour faire le moins d’effort et bien, dans le monde de l’ingénierie, c’est la même chose. Les problèmes de minimisation sont omniprésents dans de nombreux systèmes que ce soit pour obtenir un gain de temps, d’argent, d’énergie, de matière première, ou encore de satisfaction. On peut par exemple chercher à optimiser un trajet, la forme d’un objet, un prix de vente, une réaction chimique, le contrôle aérien, le rendement d’un appareil, le fonctionnement d’un moteur … La complexité des problèmes et de leur modélisation fait de l’optimisation une branche des mathématiques très vaste et variée, en pratique la qualité des résultats dépend de la pertinence du modèle, du bon choix des variables que l’on cherche à optimiser, de l’efficacité de l’algorithme et des moyens pour le traitement numérique. Dans le domaine de l’aérodynamisme, la forme des avions et des voitures de courses est souvent designer pour que l’énergie dépensée soit minimum. Après avoir introduit quelques aspects algorithmiques du problème de minimisation, l’article suivant présentera comment le profil d’une aile d’avion peut être optimisé pour maximiser ses performances.</p>

<p align="center">
   <img src="/assets/images/optimization_problems.png" width="100%" />
</p>

<h2 id="algorithmes-doptimisation">Algorithmes d’optimisation</h2>

<p>Face à la résolution d’un problème d’optimisation, une 1<sup>ère</sup> étape est d’identifier à quelle catégorie il appartient. En effet, les algorithmes sont plus ou moins adaptés pour des catégories données puisque le problème peut être continue ou discret, avec ou sans contraintes, différentiable ou non, convexe ou non … On écrit un problème d’optimisation sans contraintes simplement :</p>

\[\min_{x \in X} f(x)\]

<p>où $f$ peut être appelée fonction objectif ou fonction coût. En théorie, pour des problèmes non contraints, on peut trouver le(s) minimum(s) en regardant quand $ \nabla f(x) = 0 $ (<a href="https://fr.wikipedia.org/wiki/Conditions_d%27optimalit%C3%A9#Conditions_du_premier_ordre_sans_contrainte">condition du premier ordre</a>) et la positivité de la hessienne $H(x)$ (<a href="https://fr.wikipedia.org/wiki/Conditions_d%27optimalit%C3%A9#Conditions_du_deuxi%C3%A8me_ordre_sans_contrainte">condition du second ordre</a>). Pour un problème avec contraintes, les <a href="https://fr.wikipedia.org/wiki/Conditions_de_Karush-Kuhn-Tucker">conditions de Kuhn-Tucker</a> appliquées à la fonction <a href="https://fr.wikipedia.org/wiki/Multiplicateur_de_Lagrange">Lagrangienne</a> permettent de transformer le problème en un nouveau sans contraintes mais avec des inconnues supplémentaires.</p>

<p class="notice--primary"><strong>Note:</strong> Un problème de maximisation peut être facilement transposer en un problème de minimisation : 
\(\max_{x \in X} f(x) \Leftrightarrow \min_{x \in X} - f(x)\)</p>

<p>Pour des cas simples, on peut donc résoudre analytiquement le problème. Par exemple, lorsque $f$ a une forme quadratique, linéaire et sans contrainte, annuler le gradient revient à résoudre un système linéaire. Mais, en pratique, le gradient peut avoir une forme trop compliqué ou même la fonction $f$ peut ne pas avoir de forme analytique connue (elle peut être le résultat d’une d’EDP résolu numériquement par exemple). Il existe donc une grande variété d’<a href="https://fr.wikipedia.org/wiki/Cat%C3%A9gorie:Algorithme_d%27optimisation">algorithmes d’optimisation</a> itératifs pour essayer de trouver le minimum, certains étant plus ou moins adaptés à certains type de problème. D’autre part, il est courant de valider ces algorithmes en les testant sur des fonctions connues pour lesquelles on connaît analytiquement la valeur du vraie mimimum, elles permettent d’évaluer les caractéristiques des approches comme la vitesse de convergence, la robustesses, la précision ou le comportement général. Une liste assez complète de ces fonctions test est disponible sur <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization">wikipedia</a>.</p>

<p>Par soucis de simplicité, les 3 approches ci-dessous sont des approches simples qui permettent d’introduisent les notions basiques des algorithmes d’optimisation, elles seront testées sur la fonction test de Himmelblau. Dans la réalité, on fait le plus souvent appelle a des librairies ou logiciels spécialisés qui implémentent des approches bien plus sophistiquées.</p>

<p><em>todo : afficher fonction himmelblau - interactive 3D plotly</em></p>

<h3 id="descente-de-gradient">Descente de gradient</h3>

<p><img src="/assets/images/gradient_descent.gif" alt="image-right" class="align-right" width="45%" /> L’algorithme de descente de gradient permet de minimiser des fonctions réelles différentiables. Cette approche itérative améliore successivement le point recherché en se déplacement dans la direction opposé au gradient de façon à faire décroître la fonction objectif. Dans sa version simple, l’algorithme trouve un minimum local (et pas global) et peut présenter certains inconvénients comme par exemple la difficulté à converger si le paramètre $\alpha$ (le pas de la descente) est mal réglé. Il existe tout une famille de méthodes dites <em>à directions de descente</em> qui exploitent le gradient pour converger le minimum de $f$ de façon plus efficace.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">itermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># initialization
</span>    <span class="n">x</span><span class="p">,</span> <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x0</span><span class="p">))),</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="c1"># iterative loop
</span>    <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="n">itermax</span><span class="p">):</span>
        <span class="n">grad_fxk</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">,:])</span> <span class="c1"># use analytical expression or numerical approximation
</span>        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">grad_fxk</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p class="notice--info"><strong>Note:</strong> Si le pas de descente $\alpha$ est trop petit, l’algorithme risque de converger trop lentement (voir jamais). Si $\alpha$ est trop grand, l’algorithme peut diverger (notamment en zigzaguant dans les vallées étroites)</p>

<h3 id="nelder-mead">Nelder-Mead</h3>

<p><img src="/assets/images/nelder_mead.gif" alt="image-right" class="align-right" width="45%" /> Un problème majeur des algorithmes à directions de descente est qu’elles sont surtout efficaces pour des fonctions différentiables et lorsqu’on connaît l’expression exacte du gradient de $f$. On peut néanmoins approximer le gradient par schéma numérique mais l’approximation faite rend souvent cette approche inefficace. La méthode de Nelder-Mead est une méthode qui exploite le concept de <a href="https://fr.wikipedia.org/wiki/Simplexe">simplexe</a> : une figure de $N+1$ sommets pour un espace à $N$ dimensions. L’idée consiste, à chaque itération, d’évaluer la valeur de la fonction $f$ à chaque point du simplexe et, selon ses valeurs, effectuer des transformations géométriques du simplexe (réflexion, expansion, contraction). Par exemple, dans une vallée, le simplexe sera étiré dans la direction où $f$ diminue. Bien que simple, cet algorithme permet de trouver un minimum sans calcul de gradient cependant il est moins efficace quand la dimension d’entrée $N$ est grande.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">nelder_mead</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">itermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">params</span>   
    <span class="c1"># initialization
</span>    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">]],[</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">]],[</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mf">0.5</span><span class="p">]])</span>
    <span class="n">x</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">])</span>
    <span class="n">xm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x0</span><span class="p">)))</span>
    <span class="c1"># iterative loop
</span>    <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="n">itermax</span><span class="p">):</span>
        <span class="c1"># SORT SIMPLEX
</span>        <span class="n">A</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> 
        <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">x_bar</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">],:],</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">2</span><span class="p">],:],</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">],:]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">],:])</span><span class="o">/</span><span class="mi">2</span>
        <span class="c1"># REFLECTION
</span>        <span class="n">x_refl</span> <span class="o">=</span> <span class="n">x_bar</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">)</span>
        <span class="c1"># EXPANSION
</span>        <span class="k">if</span> <span class="n">f</span><span class="p">(</span><span class="n">x_refl</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x_min</span><span class="p">):</span> 
            <span class="n">x_exp</span> <span class="o">=</span> <span class="n">x_bar</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">f</span><span class="p">(</span><span class="n">x_exp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x_refl</span><span class="p">):</span>
                <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_exp</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_refl</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_min</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x_refl</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_refl</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x_max</span><span class="p">)):</span>
            <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_refl</span> 
        <span class="c1"># CONTRACTION
</span>        <span class="k">else</span><span class="p">:</span> 
            <span class="n">x_con</span> <span class="o">=</span> <span class="n">x_bar</span> <span class="o">-</span> <span class="p">(</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
            <span class="k">if</span> <span class="n">f</span><span class="p">(</span><span class="n">x_con</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">f</span><span class="p">(</span><span class="n">x_min</span><span class="p">):</span>
                <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_con</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">],:]</span> <span class="o">=</span> <span class="n">x_max</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">],:]</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
        <span class="c1"># UPDATE DATAs
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_max</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">],:],</span> <span class="n">x_min</span><span class="p">])</span>
        <span class="n">xm</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">x_bar</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">xm</span><span class="p">[:</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span>
</code></pre></div></div>

<p class="notice--warning"><strong>Attention:</strong> Comme la descente de gradient, la méthode de Nelder-Mead converge vers un minimum local de la fonction $f$ et non global. Il est toutefois possible de redémarrer l’algorithme avec une valeur d’initialisation $x_0$ différente pour espérer converger vers un nouveau minimum plus petit.</p>

<h3 id="stratégie-dévolution">Stratégie d’évolution</h3>

<p><img src="/assets/images/evolution_strategy.gif" alt="image-right" class="align-right" width="45%" /> Les méthodes présentées précédemment sont capables de trouver des minima mais des minima locaux et non globaux. Les techniques dites stratégies d’évolution sont des <a href="https://fr.wikipedia.org/wiki/M%C3%A9taheuristique">métaheuristiques</a> inspirées de la théorie de l’évolution qui converge statistiquement vers un minimum global. L’idée est de partir d’une population de $\mu$ <em>parents</em> qui vont produire $\lambda$ <em>enfants</em>. Parmis ces $\lambda$ enfants, seuls ceux les mieux sont sélectionné pour faire partie de la prochaine <em>génération</em>. Le vocabulaire utilisé est celui de l’évolution mais, en pratique, on fait des tirages aléatoires de points et on garde ceux pour lesquelles la fonction $f$ est minimale. Cet algorithme peut trouver un minimum global mais l’inconvénient principal est qu’il nécessite un grand nombre d’évaluation de la fonction $f$ ce qui est généralement coûteux en temps de calcul.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evolution_strategy</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">itermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># parameters
</span>    <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="n">lambd</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span> <span class="o">=</span> <span class="n">params</span>
    <span class="c1"># initialization
</span>    <span class="n">x</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)),</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">dim</span><span class="p">)),</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">itermax</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]</span>
    <span class="c1"># ITERATIVE LOOP
</span>    <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="n">itermax</span><span class="p">):</span>
        <span class="c1"># GENERATION
</span>        <span class="n">sp</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tau</span> <span class="o">*</span> <span class="n">randn</span><span class="p">(</span><span class="n">lambd</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="n">xp</span><span class="p">[</span><span class="n">k</span><span class="p">,:,:]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">+</span> <span class="n">sp</span> <span class="o">*</span> <span class="n">randn</span><span class="p">(</span><span class="n">lambd</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="n">Zp</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">xp</span><span class="p">[</span><span class="n">k</span><span class="p">,:,:]]</span>
        <span class="c1"># SELECTION
</span>        <span class="n">mins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">Zp</span><span class="p">)[:</span><span class="n">mu</span><span class="p">]</span>
        <span class="n">xc</span>   <span class="o">=</span> <span class="n">xp</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">mins</span><span class="p">,:]</span>
        <span class="n">sc</span>   <span class="o">=</span> <span class="n">sp</span><span class="p">[</span><span class="n">mins</span><span class="p">,:]</span>
        <span class="c1"># UPDATE
</span>        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">s</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[:</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span>
</code></pre></div></div>

<h2 id="problème-daérodynamisme">Problème d’aérodynamisme</h2>

<p>Imaginons qu’on veuille créer un avion d’un poids de $P=6 kg$ et qui aura une vitesse moyenne de vol de $V=12 m/s$, le problème est de designer les ailes de l’avion de telle façon que l’énergie qui sera dépensée soit minimum. Si on considère un vol stationnaire, il existe 4 forces principales qui s’opposent : la poussée (produit par les moteurs), la trainée ( due à la résistance de l’air, le profil de l’aile, la compressibilité …), le poids (gravité terrestre), et la portance (plus d’infos chez <a href="https://www.youtube.com/watch?v=r-ESaj_4ujc">science étonnante</a>). Le but de notre problème d’optimisation du profil d’aile est donc de trouver une forme d’aile qui minimisera la trainée et maximisera la portance. La portance verticale $F_y$ d’une aile et la trainée horizontale $F_x$ sont calculées grâce aux formules suivantes issues de la mécanique des fluides :</p>

\[F_y = \frac{1}{2}\, \rho\, S\, V^2\, C_y  \quad \text{et} \quad  F_x = \frac{1}{2}\, \rho\, S\, V^2\, C_x\]

<p>avec</p>
<ul>
  <li>$\rho$ la masse volumique de l’air ($kg/m^3$)</li>
  <li>$S$ la surface de l’aile ($m^2$)</li>
  <li>$V$ la vitesse ($m/s$)</li>
  <li>$C_y$ le coefficient de portance</li>
  <li>$C_x$ le coefficient de trainée</li>
</ul>

<p>Finalement, la fonction à minimiser s’écrit :</p>

\[f(x) = F_x + \max(0, P - F_y)\]

<p class="text-center">avec \(x = \left[ \text{NACA}_{M} \text{, NACA}_{P} \text{, NACA}_{XX} \text{, L, }\alpha \right]\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># constantes
</span><span class="n">poids</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">Ro</span>    <span class="o">=</span> <span class="mi">1</span>
<span class="n">V</span>     <span class="o">=</span> <span class="mi">12</span>
<span class="c1"># function to minimize
</span><span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># call xfoil
</span>    <span class="n">write_xfoil</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="n">system</span><span class="p">(</span><span class="sa">r</span><span class="s">'xfoil.exe &lt; input.dat'</span><span class="p">)</span>
    <span class="n">CL</span><span class="p">,</span> <span class="n">CD</span> <span class="o">=</span> <span class="n">read_xfoil</span><span class="p">()</span>
    <span class="c1"># compute COST function
</span>    <span class="n">L</span>  <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">c</span>  <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span><span class="o">*</span><span class="n">L</span>
    <span class="n">S</span>  <span class="o">=</span> <span class="n">L</span><span class="o">*</span><span class="n">c</span>
    <span class="n">Fx</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">Ro</span><span class="o">*</span><span class="n">S</span><span class="o">*</span><span class="n">V</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">CD</span>
    <span class="n">Fy</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">Ro</span><span class="o">*</span><span class="n">S</span><span class="o">*</span><span class="n">V</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">CL</span>
    <span class="n">y</span>  <span class="o">=</span> <span class="n">Fx</span> <span class="o">+</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">poids</span><span class="o">-</span><span class="n">Fy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></div>

<p>Les paramètres à trouver définissant la forme de l’aile sont la géométrie du profil, l’envergure $L$ de l’aile et l’<a href="https://fr.wikipedia.org/wiki/Incidence_(a%C3%A9rodynamique)">angle d’attaque</a> $\alpha$. La géométrie du profil peut être définie par le code <a href="https://fr.wikipedia.org/wiki/Profil_NACA">NACA</a> MPXX où M est la cambrure maximale, P le point de cambrure maximal par rapport au bord d’attaque de la corde, et XX l’épaisseur maximale du profil. Par exemple, le profil aérodynamique NACA 2412 possède une cambrure maximale de $2%$ à $40%$ à partir du bord d’attaque avec une épaisseur maximale de 12%. D’autres part, pour simplifier, on supposera que la corde est 10 fois plus petite que l’envergure de l’aile. Ensuite, pour pouvoir évaluer les forces $F_x$ et $F_y$, il est nécessaire de connaître les coefficients $C_y$ et $C_x$. Ces coefficients dépendent de la forme de l’aile ainsi que de grandeurs physiques comme le nombre de Mach $Ma = \frac{v}{a} = \frac{12}{340}$ et le nombre de Reynolds $Re = \frac{\rho v L}{\mu} = \frac{12L}{1.8 10^{-5}}$, l’estimation de $C_x$ et $C_y$ n’est pas un problème évident. Mais des solveurs aérodynamiques comme <a href="https://web.mit.edu/drela/Public/web/xfoil/">XFOIL</a> implémentent des outils pour calculer ces coefficients (cf <a href="http://acversailles.free.fr/documentation/08~Documentation_Generale_M_Suire/Aerodynamique/Profils/Programmes/X%20Foil/xfoil_doc.pdf">page 16</a>). L’idée est donc d’executer des commandes XFOIL et de récupérer sa sortie à chaque fois que la fonction coût $f$ doit être évaluée.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">read_xfoil</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"results.dat"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">readlines</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">CL</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">coeffs</span><span class="p">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">CD</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">coeffs</span><span class="p">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">CL</span><span class="p">,</span> <span class="n">CD</span>

<span class="k">def</span> <span class="nf">write_xfoil</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">NACAx</span><span class="p">,</span> <span class="n">NACAy</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">NACAep</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">corde</span>    <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">mach</span>     <span class="o">=</span> <span class="mi">12</span><span class="o">/</span><span class="mi">340</span>
    <span class="n">reynolds</span> <span class="o">=</span> <span class="n">corde</span><span class="o">*</span><span class="mf">12.</span><span class="o">/</span><span class="p">(</span><span class="mf">1.8</span><span class="o">*</span><span class="mf">10e-5</span><span class="p">)</span>
    <span class="c1"># write command in file
</span>    <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">"input.dat"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"plop</span><span class="se">\n</span><span class="s">g</span><span class="se">\n\n</span><span class="s">"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"naca "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">NACAx</span><span class="p">)</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">NACAy</span><span class="p">)</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">NACAep</span><span class="p">)</span><span class="o">+</span><span class="s">"</span><span class="se">\n\n</span><span class="s">oper</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"mach "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">mach</span><span class="p">)</span><span class="o">+</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"visc "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">reynolds</span><span class="p">)</span><span class="o">+</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"pacc</span><span class="se">\n</span><span class="s">results.dat</span><span class="se">\n</span><span class="s">y</span><span class="se">\n\n</span><span class="s">"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"alfa "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span><span class="o">+</span><span class="s">"</span><span class="se">\n\n</span><span class="s">quit"</span><span class="p">)</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<p>Maintenant qu’on est capable de calculer la fonction $f$ à minimiser, on peut appliquer un algorithme d’optimisation. Étant que les méthodes présentées dans la section précédente sont basiques, il n’y a pas de honte à utiliser directement des librairies comme <a href="https://docs.scipy.org/doc/scipy/reference/optimize.html">Scipy</a> qui implémente la métaheuristique du <a href="https://fr.wikipedia.org/wiki/Recuit_simul%C3%A9">recuit simulé</a> (s’inspire de processus métallurgique). Scipy possède plusieurs autres algorithmes d’optimisation mais, après expériences, c’est celui-ci qui semblait être le plus efficace.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">optimize</span><span class="p">.</span><span class="n">dual_annealing</span><span class="p">(</span><span class="n">cost_function</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
   <img src="/assets/images/optimization_airfoil.gif" width="200%" />
</p>

<p><em>todo : aerosandbox</em></p>

<p><a href="https://github.com/julienguegan/notebooks_blog/blob/main/optimisation.ipynb"><img src="https://img.shields.io/badge/voir_le_code_complet-github-black.svg?style=plastic&amp;logo=github" alt="Generic badge" /></a> <a href="https://jupyter.org/try"><img src="https://img.shields.io/badge/écrit_avec-Jupyter_notebook-orange.svg?style=plastic&amp;logo=Jupyter" alt="Generic badge" /></a> <a href="https://lbesson.mit-license.org/"><img src="https://img.shields.io/badge/License-MIT-blue.svg?style=plastic" alt="Generic badge" /></a></p>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Catégories : </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#blog" class="page__taxonomy-item" rel="tag">blog</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Mis à jour :</strong> <time datetime="2021-08-22T04:25:30+02:00">August 22, 2021</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/posts/2021-08-11-dynamique_des_populations/" class="pagination--pager" title="Dynamique des populations : écologie, EDO, logistique
">Précédent</a>
    
    
      <a href="/posts/2021-09-10-reseau_de_neurone/" class="pagination--pager" title="Réseau de Neurone : statistique, gradient, perceptron
">Suivant</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Entrez votre recherche..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Contact</strong></li>
    

    
      
        
          <li><a href="https://www.facebook.com/julien.guegan.754" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i> Facebook</a></li>
        
      
        
          <li><a href="https://github.com/julienguegan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.instagram.com/julien_guegan_/?hl=fr" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/julien-gu%C3%A9gan-852a30138/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> Linkedin</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Flux</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Blog du Julien. Propulsé par <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>



      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'julienguegan/julienguegan.github.io');
    script.setAttribute('issue-term', 'pathname');
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
